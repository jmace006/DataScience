{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability\n",
    "\n",
    "Probability can roughly be described as \"the percentage chance of an event or sequence of events occurring\".\n",
    "If you think about a coin flip intuitively, there's a 50% chance of getting heads, and a 50% chance of getting tails. This is because there are only two possible outcomes, and each event is equally likely\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating probability ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_countries = flags.shape[0]\n",
    "\n",
    "orange_probability = flags[flags[\"orange\"] == 1].shape[0]/total_countries\n",
    "stripe_probability = flags[flags[\"stripes\"] >1].shape[0]/total_countriesdef probability_of_one(num_trials, num_rolls):\n",
    "\n",
    "\n",
    "#  This function will take in the number of trials, and the number of rolls per trial.\n",
    "# Then it will conduct each trial, and record the probability of rolling a one.\n",
    "def probabilities(num_trials)\n",
    "\n",
    "    probabilities = []\n",
    "    for i in range(num_trials):\n",
    "        die_rolls = [roll() for _ in range(num_rolls)]\n",
    "        one_prob = len([d for d in die_rolls if d==1]) / num_rolls\n",
    "        probabilities.append(one_prob)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjunctive probabilities ##\n",
    "Involves a sequence of events. eg. We want to find the probability that the first flip is heads and the second flip is heads, and so on\n",
    "\n",
    "Each event in this sequence is independent, as the outcome of the first flip won't have an impact on the outcome of the last flip. All we have to do to compute the probability of this sequence is multiply the individual probabilities of each event together. This is .5 * .5 * .5 * .5 * .5, which equals .03125, giving us a 3.125% chance that all 5 coin flips result in heads\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "five_heads = .5 ** 5 \n",
    "ten_heads =  .5 ** 10\n",
    "hundred_heads = .5 ** 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependent probabilities ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember that whether a flag has red in it or not is in the `red` column.\n",
    "number_red_flags = flags[flags[\"red\"] == 1].shape[0]\n",
    "number_countries = flags.shape[0]\n",
    "\n",
    "three_red = 1\n",
    "\n",
    "for i in range(0,3):\n",
    "    \n",
    "   three_red = three_red * ( (number_red_flags - i) / (number_countries - i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disjunctive probability ##\n",
    "we want to know the probability of some event occurring or another event occurring. Let's say we're rolling a six-sided die -- the probability of rolling a 2 is 1/6.\n",
    "What if we want to know the probability of rolling a 2 or the probability of rolling a three? We actually can just add the probabilities, because both events are independent. Rolling a 2 doesn't change my odds of rolling a three next time around. Thus, the probability is 1/6 + 1/6, or 1/3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 1\n",
    "end = 18000\n",
    "\n",
    "# What are the odds of getting a number evenly divisible by 100, with no remainder? (ie 100, 200, 300, etc).\n",
    "hundred_prob = len([i for i in range(start,end+1) if i%100==0]) /end\n",
    "\n",
    "# What are the odds of getting a number evenly divisible by 70, with no remainder? (ie 70, 140, 210, etc). \n",
    "seventy_prob = len([i for i in range(start,end+1) if i%70==0]) /end\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disjunctive dependent probabilities ##\n",
    "When not mutually exclusive - 2 conditions: \n",
    "\n",
    "What if two traits are not independent -  eg. Some of the cars are red and convertibles. If we don't account for this overlap, we end up with a vastly inflated count.\n",
    "Let's say that we have 3 cars that are red and convertibles. Our probability for red or convertible then comes out to (1/2 + 1/2) - 3/10. We subtract 3/10 to account for the cars we double counted when we computed (1/2 + 1/2). This gives us a .7 probability of a car being a convertible or red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stripes_or_bars = None\n",
    "red_or_orange = None\n",
    "total_flags = flags.shape[0]\n",
    "\n",
    "red_flags = flags[flags[\"red\"] == 1].shape[0]\n",
    "orange_flags = flags[flags[\"orange\"] == 1].shape[0]\n",
    "red_and_orange_flags = flags[(flags[\"orange\"] == 1) & (flags[\"red\"] ==1)].shape[0]\n",
    "\n",
    "red_or_orange = (red_flags/total_flags) + (orange_flags/total_flags) - (red_and_orange_flags/total_flags)\n",
    "\n",
    "\n",
    "stripes = flags[flags[\"stripes\"] > 0].shape[0]\n",
    "bars = flags[flags[\"bars\"] > 0].shape[0]\n",
    "stripes_and_bars = flags[(flags[\"stripes\"] >0) & (flags[\"bars\"] >0)].shape[0]\n",
    "\n",
    "stripes_or_bars = (stripes/total_flags + bars/total_flags) - stripes_and_bars/total_flags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disjunctive probabilities with multiple conditions ##\n",
    "When not mutually exclusive - n conditions:\n",
    "\n",
    "eg. all cars that are red or convertibles or have a top speed of 130mph. One easy way to solve for cases like this is to find everything that doesn't match our criteria first\n",
    "Let's say there are 2 vehicles that are blue and sport utility vehicles and have a 110mph top speed. We would get a 1 - .2 or .8 probability for red or convertible or 130mph top speed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heads_or = None\n",
    "all_three_tails = (1/2 * 1/2 * 1/2)\n",
    "heads_or = 1 - all_three_tails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical significance:\n",
    "\n",
    "Statistical significance is a measure of whether your research findings are meaningful. More specifically, itâ€™s whether your stat closely matches what value you would expect to find in an entire population. \n",
    "You usually set a significance level beforehand that will determine if your hypothesis is true or not. After conducting the experiment, you check against the significance level to determine.\n",
    "A common significance level is .05. This means: \"only 5% or less of the time will the result have been due to chance.\n",
    "In order to test for significance, we compare our result ratio with the mean ratios.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Distributions:\n",
    "\n",
    "The pmf function in SciPy is an implementation of the mathematical probability mass function. The pmf will give us the probability of each k in our outcome_counts list occurring.\n",
    "A binomial distribution only needs two parameters. A parameter is the statistical term for a number that summarizes data for the entire population. For a binomial distribution, the parameters are:\n",
    "* N, the total number of events,\n",
    "* p, the probability of the outcome we're interested in seeing.\n",
    "The SciPy function pmf matches this and takes in the following parameters:\n",
    "* x: the list of outcomes,\n",
    "* n: the total number of events,\n",
    "* p: the probability of the outcome we're interested in seeing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a range of numbers from 0 to 30, with 31 elements (each number has one entry).\n",
    "outcome_counts = linspace(0,30,31)\n",
    "\n",
    "outcome_probs = binom.pmf(outcome_counts,30,0.39)\n",
    "plt.bar(outcome_counts,outcome_probs)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected value of Probaility Distribution (mean):\n",
    "\n",
    "The most likely result of a single sample that we look at. To compute this, we just multiplyN by p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Deviation of a Probability Distribution:\n",
    "\n",
    "How much the actual values will vary from the mean when we take a sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative density function:\n",
    "\n",
    "So far, we've looked at the probability that single values of k will occur. What we can look at instead is the probability that k or less will occur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import linspace\n",
    "from scipy.stats import binom\n",
    "\n",
    "# Create a range of numbers from 0 to 30, with 31 elements (each number has one entry).\n",
    "outcome_counts = linspace(0,30,31)\n",
    "\n",
    "# Create the cumulative binomial probabilities, one for each entry in outcome_counts.\n",
    "dist = binom.cdf(outcome_counts,30,0.39)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z Scores:\n",
    "\n",
    "The number of standard deviations away from the mean a probability is. \n",
    "These z-scores can then be used to find the percentage of values to the left and right of the value we're looking at. This is because every normal distribution, as we learned in an earlier mission, has the same properties when it comes to what percentage of the data is within a certain number of standard deviations of the mean. You can look these up in a standard normal table. About 68% of the data is within 1 standard deviation of the mean, 95% is within 2, and 99% is within 3.\n",
    "ï¿¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi Squared Test\n",
    "\n",
    "The chi-squared test enables us to quantify the difference between sets of observed and expected categorical values. We can calculate\n",
    "Ï‡2, the chi-squared value, by adding up all of the squared differences between observed and expected values.\n",
    "\n",
    "What we really want to find is one number that can tell us how much all of our observed counts deviate from all of their expected counterparts. This will let us figure out if our difference in counts is statistically significant. We can get one step closer to this by squaring the top term in our difference formula: \n",
    "\n",
    "(observed-expected) 2\n",
    "/\n",
    "expected\n",
    "\n",
    "Chi-squared values for the same sized effect increase as sample size increases, but the chance of getting a high chi-squared value decreases as the sample gets larger.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare\n",
    "import numpy as np\n",
    "\n",
    "observed_list = [27816,3124,1039,311,271]\n",
    "expected_list = [26146.5,3939.9,944.3,260.5,1269.8]\n",
    "\n",
    "chisquare_value, race_pvalue = chisquare(observed_list,expected_list)\n",
    "\n",
    "#Multiple Category Chi Square Tests (with Crosstab)\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "chisq_value, pvalue_gender_race, df, expected = chi2_contingency(pandas.crosstab(income[\"sex\"], [income[\"race\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crosstabs:\n",
    "\n",
    "The crosstab function will print a table that shows frequency counts for two or more columns. Here's how you could use the pandas.crosstab function:\n",
    "â€¦bit like a big group by!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "table = pandas.crosstab(income[\"sex\"], [income[\"high_income\"]])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contingency:\n",
    "\n",
    "generate the expected values, use the scipy.stats.chi2_contingency function to do this. The function takes in a cross table of observed counts, and returns the chi-squared value, the p-value, the degrees of freedom, and the expected frequencies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations:\n",
    "\n",
    "Correlations tell us how closely related two columns are. We'll be using the r value, also called Pearson's correlation coefficient, which measures how closely two sequences of numbers are correlated.\n",
    "\n",
    "An r value falls between -1 and 1. \n",
    "\n",
    "The value tells us whether two columns are positively correlated, not correlated, or negatively correlated. \n",
    "- The closer to 1 the r value is, the stronger the positive correlation between the two columns. \n",
    "- The closer to -1 the r value is, the stronger the negative correlation (i.e., the more \"opposite\" the columns are). \n",
    "- The closer to 0, the weaker the correlation. \n",
    "\n",
    "In general, r values above .25 or below -.25 are enough to qualify a correlation as interesting. An r value isn't perfect, and doesn't indicate that there's a correlation -- just the possiblity of one. \n",
    "\n",
    "To really assess whether or not a correlation exists, we need to look at the data using a scatterplot to see its \"shape.\" \n",
    "\n",
    "NOTE: We can use the pandas pandas.DataFrame.corr() method to find correlations between columns in a dataframe. The method returns a new dataframe where the index for each column and row is the name of a column in the original data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pearsonr function will find the correlation between two columns of data.\n",
    "# It returns the r value and the p value.  We'll learn more about p values later on.\n",
    "r, p_value = pearsonr(nba_stats[\"fga\"], nba_stats[\"pts\"])\n",
    "# As we can see, this is a very high positive r value - it's close to 1.\n",
    "print(r)\n",
    "\n",
    "# These two columns are much less correlated.\n",
    "r, p_value = pearsonr(nba_stats[\"trb\"], nba_stats[\"ast\"])\n",
    "# We get a much lower, but still positive, r value.\n",
    "print(r)\n",
    "\n",
    "r_fta_pts, p_value = pearsonr(nba_stats[\"fta\"], nba_stats[\"pts\"])\n",
    "print(r)\n",
    "\n",
    "r_stl_pf, p_value = pearsonr(nba_stats[\"stl\"], nba_stats[\"pf\"])\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probaility Distribution Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Bikesharing distribution ##\n",
    "\n",
    "import pandas\n",
    "bikes = pandas.read_csv(\"data/bike_rental_day.csv\")\n",
    "\n",
    "number_of_days = len(bikes)\n",
    "prob_over_5000 = bikes[bikes[\"cnt\"] >5000 ].shape[0]/number_of_days\n",
    "\n",
    "## 4. Computing the distribution ##\n",
    "\n",
    "import math\n",
    "\n",
    "# Each item in this list represents one k, starting from 0 and going up to and including 30.\n",
    "outcome_counts = list(range(31))\n",
    "\n",
    "def find_combinations(N,k):\n",
    "     # Calculate the numerator of our formula.\n",
    "    numerator = math.factorial(N)\n",
    "    # Calculate the denominator.\n",
    "    denominator = math.factorial(k) * math.factorial(N - k)\n",
    "    # Divide them to get the final value.\n",
    "    return numerator / denominator\n",
    "\n",
    "p = .39\n",
    "q = .61\n",
    "N = 30\n",
    "\n",
    "def single_probability(N,k, p, q):\n",
    "   \n",
    "    return (p ** k) * (q ** (N-k))\n",
    "\n",
    "outcome_probs=[]\n",
    "\n",
    "for i in outcome_counts:\n",
    "    \n",
    "    probability = single_probability(N,i,p,q)\n",
    "    combinations = find_combinations(N,i)\n",
    "    \n",
    "    outcome_probs.append(probability * combinations)\n",
    "\n",
    "\n",
    "## 5. Plotting the distribution ##\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# The most likely number of days is between 10 and 15.\n",
    "plt.bar(outcome_counts, outcome_probs)\n",
    "plt.show()\n",
    "\n",
    "## 6. Simplifying the computation ##\n",
    "\n",
    "import scipy\n",
    "from scipy import linspace\n",
    "from scipy.stats import binom\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a range of numbers from 0 to 30, with 31 elements (each number has one entry).\n",
    "outcome_counts = linspace(0,30,31)\n",
    "\n",
    "outcome_probs = binom.pmf(outcome_counts,30,0.39)\n",
    "plt.bar(outcome_counts,outcome_probs)\n",
    "plt.show\n",
    "\n",
    "## 8. Computing the mean of a probability distribution ##\n",
    "\n",
    "dist_mean = None\n",
    "\n",
    "dist_mean = 30 * 0.39\n",
    "\n",
    "## 9. Computing the standard deviation ##\n",
    "\n",
    "dist_stdev = None\n",
    "\n",
    "dist_stdev = (30 * 0.39 * 0.61) ** (1/2)\n",
    "\n",
    "## 10. A different plot ##\n",
    "\n",
    "# Enter your answer here.\n",
    "outcome_counts = linspace(0,10,11)\n",
    "outcome_probs = binom.pmf(outcome_counts,10,0.39)\n",
    "plt.bar(outcome_counts,outcome_probs)\n",
    "plt.show()\n",
    "\n",
    "outcome_counts = linspace(0,100,101)\n",
    "outcome_probs = binom.pmf(outcome_counts,100,0.39)\n",
    "plt.bar(outcome_counts,outcome_probs)\n",
    "plt.show()\n",
    "\n",
    "## 11. The normal distribution ##\n",
    "\n",
    "# Create a range of numbers from 0 to 100, with 101 elements (each number has one entry).\n",
    "outcome_counts = scipy.linspace(0,100,101)\n",
    "\n",
    "# Create a probability mass function along the outcome_counts.\n",
    "outcome_probs = binom.pmf(outcome_counts,100,0.39)\n",
    "\n",
    "# Plot a line, not a bar chart.\n",
    "plt.plot(outcome_counts, outcome_probs)\n",
    "plt.show()\n",
    "\n",
    "## 12. Cumulative density function ##\n",
    "\n",
    "outcome_counts = linspace(0,30,31)\n",
    "\n",
    "outcome_probs = binom.cdf(outcome_counts,30,0.39)\n",
    "\n",
    "plt.plot(outcome_counts, outcome_probs)\n",
    "\n",
    "## 14. Faster way to calculate likelihood ##\n",
    "\n",
    "left_16 = None\n",
    "right_16 = None\n",
    "\n",
    "left_16 = binom.cdf(16,30,0.39)\n",
    "right_16 = 1 - left_16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
